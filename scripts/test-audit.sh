#!/bin/bash
# Canonical Test Audit Script (v10)
# Single Source of Truth for all quality checks.
# Supports staged execution for CI and a full local run.
set -euo pipefail
trap 'echo "‚ùå An error occurred. Aborting test audit." >&2' ERR

# --- Configuration ---
E2E_TEST_DIR="tests/e2e"
ARTIFACTS_DIR="./test-support"
CI_SHARD_COUNT=4

# --- Helper Functions ---
ensure_artifacts_dir() {
    mkdir -p "$ARTIFACTS_DIR"
}

# --- Stage Functions ---

run_preflight() {
    echo "‚úÖ [1/6] Running Preflight Checks..."
    ./scripts/preflight.sh
    echo "‚úÖ [1/6] Preflight Checks Passed."
}

run_quality_checks() {
    echo "‚úÖ [2/6] Running Code Quality Checks Sequentially..."
    
    echo "Running Lint..."
    if ! pnpm lint; then
        echo "‚ùå Lint failed." >&2
        exit 1
    fi

    echo "Running Typecheck..."
    if ! pnpm typecheck; then
        echo "‚ùå Typecheck failed." >&2
        exit 1
    fi

    echo "Running Unit Tests..."
    if ! pnpm test; then
        echo "‚ùå Unit Tests failed." >&2
        exit 1
    fi
    
    # Move metrics file to root for CI artifact upload
    if [ -f "frontend/unit-metrics.json" ]; then
        mv frontend/unit-metrics.json .
        echo "‚ÑπÔ∏è Moved unit-metrics.json to root."
    else
        echo "‚ö†Ô∏è Warning: frontend/unit-metrics.json not found."
    fi
    
    echo "‚ÑπÔ∏è Lint/Typecheck/Test completed successfully."
    echo "‚úÖ [2/6] Code Quality Checks Passed."
}

run_build() {
    echo "‚úÖ [3/6] Building Application for E2E Tests..."
    pnpm build:test || {
        echo "‚ùå Build failed." >&2
        exit 1
    }
    echo "‚ÑπÔ∏è Build output located in ./frontend/dist"
    echo "‚úÖ [3/6] Build Succeeded."
}



run_prepare_stage() {
    echo "üîê Validating environment variables..."
    node scripts/validate-env.mjs
    run_preflight
    run_quality_checks
    run_build
}

run_e2e_tests_shard() {
    local SHARD_NUM=$1
    local TOTAL_SHARDS=4  # Fixed to match CI matrix

    echo "‚úÖ Running E2E Test Shard ${SHARD_NUM}/${TOTAL_SHARDS}..."
    
    # Ensure build artifact exists (required for preview:test)
    if [ ! -d "frontend/dist" ]; then
        echo "üì¶ Building test artifact..."
        pnpm run build:test
    fi

    # Run Playwright with native sharding
    # Playwright expects 1-indexed shards
    # Use PLAYWRIGHT_BLOB_OUTPUT_DIR env var to output blobs to unique dir per shard
    PLAYWRIGHT_BLOB_OUTPUT_DIR="blob-report/shard-${SHARD_NUM}" \
        pnpm exec playwright test tests/e2e --shard="${SHARD_NUM}/${TOTAL_SHARDS}" --reporter=blob

    echo "‚úÖ E2E Test Shard ${SHARD_NUM} Passed."
}

run_e2e_tests_all() {
    echo "‚úÖ [4/6] Running ALL E2E Tests (local mode)..."
    pnpm exec playwright test $E2E_TEST_DIR || {
        echo "‚ùå E2E full suite failed." >&2
        exit 1
    }
    echo "‚úÖ [4/6] E2E Tests Passed."
}

run_e2e_health_check() {
    echo "‚úÖ [4/6] Running Core Journey (Canonical Health Check)..."
    pnpm exec playwright test tests/e2e/core-journey.e2e.spec.ts --project=chromium || {
        echo "‚ùå Health Check failed." >&2
        exit 1
    }
    echo "‚úÖ [4/6] Health Check Passed."
}

run_lighthouse_ci() {
    echo "‚úÖ [5/6] Running Lighthouse CI..."
    
    # Ensure build exists
    if [ ! -d "frontend/dist" ]; then
        echo "üì¶ Building for Lighthouse..."
        pnpm build:test
    fi
    
    # Run Lighthouse
    echo "üî¶ Generating Lighthouse Config..."
    node scripts/generate-lhci-config.js
    
    echo "üî¶ Running lhci autorun..."
    # Capture exit code to ensure cleanup
    set +e
    NODE_NO_WARNINGS=1 npx lhci autorun --config=lighthouserc.json
    EXIT_CODE=$?
    set -e
    
    if [ $EXIT_CODE -ne 0 ]; then
        echo "‚ùå Lighthouse CI failed (Scores below threshold)." >&2
        # We still want to print the scores if possible
    fi

    # Parse and print scores
    node scripts/process-lighthouse-report.js

    if [ $EXIT_CODE -ne 0 ]; then
        exit $EXIT_CODE
    fi
    
    echo "‚úÖ [5/6] Lighthouse CI Passed."
}

run_sqm_report_ci() {
    echo "‚úÖ [6/6] Generating Final Report and Updating Docs..."
    echo "‚ÑπÔ∏è Merging metrics + updating PRD‚Ä¶"
    ensure_artifacts_dir
    if [ -f "./scripts/run-metrics.sh" ]; then
        ./scripts/run-metrics.sh
        node scripts/update-prd-metrics.mjs
    else
        echo "‚ö†Ô∏è Warning: Metric generation scripts not found. Skipping report."
    fi
    echo "‚úÖ [6/6] Reporting complete."
}

run_sqm_report_local() {
    echo "‚úÖ [6/6] Generating and Printing SQM Report..."
    if [ -f "./scripts/run-metrics.sh" ]; then
        ./scripts/run-metrics.sh
        echo "‚ÑπÔ∏è  Formatting Console Output..."
        node scripts/print-metrics.mjs
    else
        echo "‚ö†Ô∏è Warning: Metric generation scripts not found. Skipping SQM report."
    fi
    echo "‚úÖ [6/6] SQM Report Generation Complete."
}

run_ci_simulation() {
    echo "ü§ñ Running Full CI Simulation..."
    
    # Clean up previous runs
    rm -rf test-results merged-reports blob-report
    

    
    # 1. Setup (Match GitHub CI "prepare" job steps)
    echo "üîß CI Setup: Installing dependencies..."
    pnpm install --frozen-lockfile
    
    echo "üîß CI Setup: Installing Playwright browsers..."
    pnpm exec playwright install --with-deps chromium

    # 2. Run Prepare Stage
    run_prepare_stage
    
    # 3. Run Shards (Fixed to 4 like CI matrix)
    local TOTAL_SHARDS=4
    echo "üîÑ Running $TOTAL_SHARDS shards..."
    
    for ((shard=1; shard<=TOTAL_SHARDS; shard++)); do
        echo "üß™ Running shard ${shard}/${TOTAL_SHARDS}..."
        run_e2e_tests_shard "$shard"
    done
    
    # 4. Merge reports if blob reports exist
    echo "üîÑ Merging reports..."
    mkdir -p merged-reports test-results/playwright
    
    if [ -d "blob-report" ] && [ "$(ls -A blob-report 2>/dev/null)" ]; then
        # Count tests from each shard directory
        local total_passed=0
        local total_failed=0
        local total_skipped=0
        
        for shard_dir in blob-report/shard-*; do
            if [ -d "$shard_dir" ]; then
                # Look for the blob zip file in each shard directory
                for zip_file in "$shard_dir"/*.zip; do
                    if [ -f "$zip_file" ]; then
                        # Extract and count from report.jsonl (JSONL format)
                        # Count onTestEnd events by status (clean output with tr)
                        local passed_raw=$(unzip -p "$zip_file" report.jsonl 2>/dev/null | grep -c '"method":"onTestEnd".*"status":"passed"' 2>/dev/null | tr -d '[:space:]')
                        local failed_raw=$(unzip -p "$zip_file" report.jsonl 2>/dev/null | grep -c '"method":"onTestEnd".*"status":"failed"' 2>/dev/null | tr -d '[:space:]')
                        local skipped_raw=$(unzip -p "$zip_file" report.jsonl 2>/dev/null | grep -c '"method":"onTestEnd".*"status":"skipped"' 2>/dev/null | tr -d '[:space:]')
                        # Default to 0 if empty
                        local passed=${passed_raw:-0}
                        local failed=${failed_raw:-0}
                        local skipped=${skipped_raw:-0}
                        total_passed=$((total_passed + passed))
                        total_failed=$((total_failed + failed))
                        total_skipped=$((total_skipped + skipped))
                        echo "  üìä Shard $(basename $shard_dir): $passed passed, $failed failed, $skipped skipped"
                    fi
                done
            fi
        done
        
        echo "  üìä Total: $total_passed passed, $total_failed failed, $total_skipped skipped"
        
        # Create the aggregated JSON for metrics
        echo "{\"stats\": {\"expected\": $total_passed, \"unexpected\": $total_failed, \"skipped\": $total_skipped}}" > test-results/playwright/results.json
        echo "‚úÖ Merged reports."
    else
        echo "‚ö†Ô∏è No blob reports to merge."
    fi
    
    # 5. Lighthouse
    run_lighthouse_ci
    
    run_sqm_report_ci
    echo "‚úÖ CI Simulation Complete."
}


# --- Main Execution Logic ---
STAGE=${1:-"local"}

echo "üöÄ Starting Test Audit (Stage: $STAGE)..."
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "üìä SpeakSharp Test Audit Pipeline"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

case $STAGE in
    prepare)
        run_prepare_stage
        echo "üéâ Prepare stage SUCCEEDED."
        ;;
    test)
        if [ -z "${2-}" ]; then
            echo "‚ùå Error: 'test' stage requires a shard index argument." >&2
            exit 1
        fi
        run_e2e_tests_shard "$2"
        echo "üéâ Test stage SUCCEEDED for shard $2."
        ;;
    report)
        run_sqm_report_ci
        echo "üéâ Report stage SUCCEEDED."
        ;;
    health-check)
        run_preflight
        echo "‚è≠Ô∏è  [2/6] Skipping Code Quality Checks (Fast Mode)"
        run_build
        run_e2e_health_check
        echo "‚è≠Ô∏è  [5/6] Skipping Lighthouse CI (Fast Mode)"
        run_sqm_report_local
        echo "üéâ Health-Check SUCCEEDED."
        ;;
    local)
        # Unset CI to ensure local-friendly behaviors (e.g., JSON reporter, non-fatal E2E check)
        unset CI
        START_TIME=$(date +%s)
        run_preflight
        run_quality_checks
        run_build
        run_e2e_tests_all
        END_TIME=$(date +%s)
        TOTAL_RUNTIME=$((END_TIME - START_TIME))
        export TOTAL_RUNTIME_SECONDS=$TOTAL_RUNTIME
        run_sqm_report_local
        echo "üéâüéâüéâ"
        echo "‚úÖ SpeakSharp Local Test Audit SUCCEEDED!"
        echo "‚è±Ô∏è  Total Runtime: ${TOTAL_RUNTIME}s"
        echo "üéâüéâüéâ"
        ;;
    ci-simulate)
        run_ci_simulation
        echo "üéâüéâüéâ"
        echo "‚úÖ SpeakSharp CI Simulation SUCCEEDED!"
        echo "üéâüéâüéâ"
        ;;
    *)
        echo "‚ùå Unknown stage: $STAGE" >&2
        echo "Usage: $0 {prepare|test <shard_index>|report|health-check|local}"
        exit 1
        ;;
esac
